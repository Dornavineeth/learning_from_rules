{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2f0c822-6bf1-4b79-b3be-585af7a97589",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dorna/CS726/project/aml/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from snorkel.preprocess import preprocessor\n",
    "from snorkel.labeling import LabelingFunction\n",
    "from snorkel.labeling import labeling_function\n",
    "from snorkel.preprocess.nlp import SpacyPreprocessor\n",
    "from snorkel.labeling.lf.nlp import nlp_labeling_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58c37e59-275f-4aef-83da-300e04ef9e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSTAIN = -1\n",
    "HAM = 0\n",
    "SPAM = 1\n",
    "\n",
    "@labeling_function()\n",
    "def check(x):\n",
    "    return SPAM if \"check\" in x.text.lower() else ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def check_out(x):\n",
    "    return SPAM if \"check out\" in x.text.lower() else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def regex_check_out(x):\n",
    "    return SPAM if re.search(r\"check.*out\", x.text, flags=re.I) else ABSTAIN\n",
    "\n",
    "'''============================================================================================='''\n",
    "\n",
    "@preprocessor(memoize=True)\n",
    "def textblob_sentiment(x):\n",
    "    scores = TextBlob(x.text)\n",
    "    x.polarity = scores.sentiment.polarity\n",
    "    x.subjectivity = scores.sentiment.subjectivity\n",
    "    return x\n",
    "\n",
    "@labeling_function(pre=[textblob_sentiment])\n",
    "def textblob_polarity(x):\n",
    "    return HAM if x.polarity > 0.9 else ABSTAIN\n",
    "\n",
    "@labeling_function(pre=[textblob_sentiment])\n",
    "def textblob_subjectivity(x):\n",
    "    return HAM if x.subjectivity >= 0.5 else ABSTAIN\n",
    "\n",
    "'''============================================================================================='''\n",
    "\n",
    "# @nlp_labeling_function()\n",
    "# def has_person_nlp(x):\n",
    "#     \"\"\"Ham comments mention specific people and are short.\"\"\"\n",
    "#     if len(x.doc) < 20 and any([ent.label_ == \"PERSON\" for ent in x.doc.ents]):\n",
    "#         return HAM\n",
    "#     else:\n",
    "#         return ABSTAIN\n",
    "\n",
    "'''============================================================================================='''    \n",
    "\n",
    "def keyword_lookup(x, keywords, label):\n",
    "    if any(word in x.text.lower() for word in keywords):\n",
    "        return label\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "def make_keyword_lf(keywords, label=SPAM):\n",
    "    return LabelingFunction(\n",
    "        name=f\"keyword_{keywords[0]}\",\n",
    "        f=keyword_lookup,\n",
    "        resources=dict(keywords=keywords, label=label),\n",
    "    )\n",
    "\n",
    "\n",
    "\"\"\"Spam comments talk about 'my channel', 'my video', etc.\"\"\"\n",
    "keyword_my = make_keyword_lf(keywords=[\"my\"])\n",
    "\n",
    "\"\"\"Spam comments ask users to subscribe to their channels.\"\"\"\n",
    "keyword_subscribe = make_keyword_lf(keywords=[\"subscribe\"])\n",
    "\n",
    "\"\"\"Spam comments post links to other channels.\"\"\"\n",
    "keyword_link = make_keyword_lf(keywords=[\"http\"])\n",
    "\n",
    "\"\"\"Spam comments make requests rather than commenting.\"\"\"\n",
    "keyword_please = make_keyword_lf(keywords=[\"please\", \"plz\"])\n",
    "\n",
    "\"\"\"Ham comments actually talk about the video's content.\"\"\"\n",
    "keyword_song = make_keyword_lf(keywords=[\"song\"], label=HAM)\n",
    "\n",
    "@labeling_function()\n",
    "def short_comment(x):\n",
    "    \"\"\"Ham comments are often short, such as 'cool video!'\"\"\"\n",
    "    return HAM if len(x.text.split()) < 5 else ABSTAIN\n",
    "\n",
    "lfs = [\n",
    "    keyword_my,\n",
    "    keyword_subscribe,\n",
    "    keyword_link,\n",
    "    keyword_please,\n",
    "    keyword_song,\n",
    "    regex_check_out,\n",
    "    short_comment,\n",
    "#     has_person_nlp,\n",
    "    textblob_polarity,\n",
    "    textblob_subjectivity,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f466ab5f-fc95-4a56-8492-ec0e3a8880ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd027fd0-c815-4216-8020-f6a0ae7fad01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1586/1586 [00:01<00:00, 973.17it/s] \n",
      "100%|██████████| 100/100 [00:00<00:00, 8414.36it/s]\n",
      "100%|██████████| 198/198 [00:00<00:00, 6772.56it/s]\n",
      "100%|██████████| 250/250 [00:00<00:00, 6149.65it/s]\n"
     ]
    }
   ],
   "source": [
    "DIR = 'data/YouTube-Spam-Collection-v1'\n",
    "\n",
    "df_U = pd.read_csv(DIR+'/'+'U_data.csv')\n",
    "U_L = applier.apply(df=df_U)\n",
    "with open(DIR+'/'+'U_L.npy', 'wb') as f:\n",
    "    np.save(f, U_L)\n",
    "\n",
    "\n",
    "df_L = pd.read_csv(DIR+'/'+'L_data.csv')\n",
    "L_L = applier.apply(df=df_L)\n",
    "with open(DIR+'/'+'L_L.npy', 'wb') as f:\n",
    "    np.save(f, L_L)\n",
    "\n",
    "df_V = pd.read_csv(DIR+'/'+'V_data.csv')\n",
    "V_L = applier.apply(df=df_V)\n",
    "with open(DIR+'/'+'V_L.npy', 'wb') as f:\n",
    "    np.save(f, V_L)\n",
    "\n",
    "df_test = pd.read_csv(DIR+'/'+'test_data.csv')\n",
    "test_L = applier.apply(df=df_test)\n",
    "with open(DIR+'/'+'test_L.npy', 'wb') as f:\n",
    "    np.save(f, test_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5809760b-254f-4650-8215-d3674e8704bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1, -1, -1, ..., -1, -1, -1],\n",
       "       [ 1,  1, -1, ..., -1, -1, -1],\n",
       "       [-1, -1, -1, ..., -1, -1, -1],\n",
       "       ...,\n",
       "       [-1,  1, -1, ..., -1, -1,  0],\n",
       "       [-1, -1, -1, ..., -1, -1,  0],\n",
       "       [-1, -1, -1, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c491edab-680d-4867-aabb-03b42d99285c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>keyword_my</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.198613</td>\n",
       "      <td>0.184111</td>\n",
       "      <td>0.106557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword_subscribe</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.127364</td>\n",
       "      <td>0.106557</td>\n",
       "      <td>0.066204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword_http</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.119168</td>\n",
       "      <td>0.097730</td>\n",
       "      <td>0.078184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword_please</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.112232</td>\n",
       "      <td>0.109079</td>\n",
       "      <td>0.055485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword_song</th>\n",
       "      <td>4</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.141866</td>\n",
       "      <td>0.108449</td>\n",
       "      <td>0.043506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regex_check_out</th>\n",
       "      <td>5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.233922</td>\n",
       "      <td>0.127364</td>\n",
       "      <td>0.080076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_comment</th>\n",
       "      <td>6</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.225725</td>\n",
       "      <td>0.137453</td>\n",
       "      <td>0.074401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textblob_polarity</th>\n",
       "      <td>7</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.035309</td>\n",
       "      <td>0.030265</td>\n",
       "      <td>0.005044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textblob_subjectivity</th>\n",
       "      <td>8</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.357503</td>\n",
       "      <td>0.243380</td>\n",
       "      <td>0.160151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       j Polarity  Coverage  Overlaps  Conflicts\n",
       "keyword_my             0      [1]  0.198613  0.184111   0.106557\n",
       "keyword_subscribe      1      [1]  0.127364  0.106557   0.066204\n",
       "keyword_http           2      [1]  0.119168  0.097730   0.078184\n",
       "keyword_please         3      [1]  0.112232  0.109079   0.055485\n",
       "keyword_song           4      [0]  0.141866  0.108449   0.043506\n",
       "regex_check_out        5      [1]  0.233922  0.127364   0.080076\n",
       "short_comment          6      [0]  0.225725  0.137453   0.074401\n",
       "textblob_polarity      7      [0]  0.035309  0.030265   0.005044\n",
       "textblob_subjectivity  8      [0]  0.357503  0.243380   0.160151"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "\n",
    "LFAnalysis(L=U_L, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56e5040c-d98e-4f0e-9d4c-4d9eab290a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 2, 2, 1, 0, 1, 1, 1, 1, 1, 3, 1, 2, 1, 1, 2, 1, 2, 0, 1,\n",
       "       1, 2, 2, 1, 4, 1, 0, 1, 1, 1, 3, 1, 2, 1, 2, 1, 3, 2, 1, 3, 3, 2,\n",
       "       3, 2, 0, 3, 4, 1, 4, 1, 1, 0, 1, 0, 0, 0, 2, 1, 1, 2, 1, 3, 1, 2,\n",
       "       0, 2, 4, 3, 1, 0, 2, 1, 2, 3, 1, 1, 1, 2, 4, 1, 1, 1, 3, 3, 2, 0,\n",
       "       1, 1, 1, 1, 2, 1, 1, 0, 1, 2, 2, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82590bb-cd96-4548-afdd-4db11142e3ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml",
   "language": "python",
   "name": "aml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
